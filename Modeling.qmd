---
title: "Modeling: Diabetes Prediction"
format: html
toc: true
toc-depth: 3
---
```{r}
library(tidyverse)
library(tidymodels)
library(janitor)
library(yardstick)

tidymodels_prefer()
```


```{r}

data <- read_csv("data/diabetes_012_health_indicators_BRFSS2015.csv")
```


# Introduction

This document builds predictive models for the **Diabetes_binary** outcome created in the EDA.  
Our goal is to compare two supervised learning methods:

1. **Classification Tree**  
2. **Random Forest**

We evaluate models using **log-loss** through 5-fold cross-validation.  
The final step is selecting the best model based on test-set performance.

Loading Data and recreating the binary variable 
```{r}
# Load the dataset
data <- read_csv("data/diabetes_012_health_indicators_BRFSS2015.csv")

# Create binary diabetes variable
data <- data %>%
  mutate(
    Diabetes_binary = ifelse(Diabetes_012 == 0, 0, 1),
    Diabetes_binary = factor(Diabetes_binary, labels = c("No", "Yes"))
  )
```


Convert Predictors to Factors
```{r}
data <- data %>%
  mutate(
    HighBP = factor(HighBP, labels = c("No", "Yes")),
    HighChol = factor(HighChol, labels = c("No", "Yes")),
    CholCheck = factor(CholCheck, labels = c("No", "Yes")),
    Smoker = factor(Smoker, labels = c("No", "Yes")),
    Stroke = factor(Stroke, labels = c("No", "Yes")),
    HeartDiseaseorAttack = factor(HeartDiseaseorAttack, labels = c("No", "Yes")),
    PhysActivity = factor(PhysActivity, labels = c("No", "Yes")),
    Fruits = factor(Fruits, labels = c("No", "Yes")),
    Veggies = factor(Veggies, labels = c("No", "Yes")),
    HvyAlcoholConsump = factor(HvyAlcoholConsump, labels = c("No", "Yes")),
    AnyHealthcare = factor(AnyHealthcare, labels = c("No", "Yes")),
    NoDocbcCost = factor(NoDocbcCost, labels = c("No", "Yes")),
    DiffWalk = factor(DiffWalk, labels = c("No", "Yes")),
    Sex = factor(Sex, labels = c("Female", "Male")),
    GenHlth = factor(GenHlth),
    Education = factor(Education),
    Income = factor(Income)
  )
```

Splitting data 

```{r}
set.seed(123)

data_split <- initial_split(data, prop = 0.7, strata = Diabetes_binary)
train_data <- training(data_split)
test_data  <- testing(data_split)
```

Now, Creating recipe

```{r}
diabetes_recipe <- recipe(Diabetes_binary ~ HighBP + HighChol + BMI + Age + Smoker +
                            HeartDiseaseorAttack + PhysActivity + GenHlth + DiffWalk,
                          data = train_data) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())
```

# Classification Tree 

```{r}
set.seed(123)
folds <- vfold_cv(train_data, v = 5, strata = Diabetes_binary)
```

```{r}
tree_spec <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune()
) %>%
  set_engine("rpart") %>%
  set_mode("classification")
```

```{r}

tree_workflow <- workflow() %>%
  add_model(tree_spec) %>%
  add_recipe(diabetes_recipe)
```

```{r}
tree_grid <- grid_regular(
  cost_complexity(range = c(-5, -1)),
  tree_depth(range = c(3, 10)),
  levels = 5
)
```

```{r}
mn_log_loss
```


```{r}
set.seed(123)
tree_tuned <- tune_grid(
  tree_workflow,
  resamples = folds,
  grid = tree_grid,
  metrics = metric_set(mn_log_loss)
)


```

## Checking the tuning results 

This will list the top 5 parameter combinations (lowest log-loss).
```{r}
show_best(tree_tuned, metric = "mn_log_loss", n = 5)
```


```{r}
best_tree <- select_best(tree_tuned, metric = "mn_log_loss")
best_tree
```
This gives you:

the best cost_complexity

the best tree_depth

Finalising the workflow 

```{r}
final_tree_workflow <- finalize_workflow(tree_workflow, best_tree)
final_tree_fit <- fit(final_tree_workflow, data = train_data)
```

```{r}
tree_preds <- predict(final_tree_fit, test_data, type = "prob") %>%
  bind_cols(test_data %>% select(Diabetes_binary))

mn_log_loss(tree_preds, truth = Diabetes_binary, .pred_No)

mn_log_loss(tree_preds, truth = Diabetes_binary, .pred_Yes)
```


# Random Forest 

```{r}
rf_spec <- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = 5
) %>%
  set_engine("ranger") %>%
  set_mode("classification")
```

Creating the workflow 

```{r}
rf_workflow <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(diabetes_recipe)
```

Tuning 

```{r}
rf_grid <- tibble(mtry = c(3, 5, 7, 10, 15))
```

```{r}
set.seed(123)

train_small <- train_data %>% sample_frac(0.20)

folds_small <- vfold_cv(train_small, v = 5, strata = Diabetes_binary)

rf_grid <- tibble(mtry = c(5, 10))

rf_spec <- rand_forest(
  mtry = tune(),
  trees = 200,
  min_n = 5
) %>% 
  set_engine("ranger") %>% 
  set_mode("classification")

rf_workflow <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(diabetes_recipe)

rf_tuned <- tune_grid(
  rf_workflow,
  resamples = folds_small,
  grid = rf_grid,
  metrics = metric_set(mn_log_loss)
)

```


## Checking the tuning results 
Top Random Forest Models 

```{r}
show_best(rf_tuned, metric = "mn_log_loss", n = 5)
```


Selecting the best random forest model 

```{r}
best_rf <- select_best(rf_tuned, metric = "mn_log_loss")
best_rf
```

Finalising the RF Model 

```{r}
final_rf_workflow <- finalize_workflow(rf_workflow, best_rf)
```

```{r}
final_rf_fit <- fit(final_rf_workflow, data = train_data)
```

```{r}
rf_preds <- predict(final_rf_fit, test_data, type = "prob") %>%
  bind_cols(test_data %>% select(Diabetes_binary))

colnames(rf_preds)
mn_log_loss(rf_preds, truth = Diabetes_binary, .pred_No)
mn_log_loss(rf_preds, truth = Diabetes_binary, .pred_Yes)


```
# Final Model Selection

After tuning and evaluating both models, we compare their performance on the test set using the
`mn_log_loss` metric.

- **Classification Tree log-loss:** 0.3590  
- **Random Forest log-loss:** 0.3482  

Because a lower log-loss indicates a better predictive model, the **Random Forest model is selected as
our final model**. This model will be refit on the entire dataset in the API script and will serve as the
model deployed through the plumber API and Docker container.

The Random Forest provides improved predictive accuracy due to its ability to aggregate many weak
learners and reduce variance compared to a single classification tree. Given the size and complexity of the
dataset, this behavior aligns with expectations.

